{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBQSoCejsu4G"
   },
   "source": [
    "# Demo 3: Gemini Exercise\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ciri/persona-workshop/blob/main/demo-3/Silicon-Gemini-Exercise.ipynb)\n",
    "\n",
    "We will start by setting-up the notebook. If you haven't already, first create a Gemini API key [here](https://www.google.com/url?q=https%3A%2F%2Faistudio.google.com%2Fapp%2Fapikey) (free). The free version is somewhat limited (see quotas [here](https://cloud.google.com/gemini/docs/quotas#daily)), but if you add your card information you get $300 free credit for the next 90 days (you don't need to do this for the workshop). You can then add it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVtugDSGt_gy",
    "outputId": "1ae02ec2-24b8-448e-8631-819ce57bc08c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n",
      "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.170.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv\n",
    "!pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZPA6wNSqsu4H"
   },
   "outputs": [],
   "source": [
    "# Libraries that we will use, if you are missing a library,\n",
    "# create a new cell with e.g.:\n",
    "# !pip install NAME_OF_MISSING\n",
    "# where NAME_OF_MISSING is the library that you are missing.\n",
    "import typing\n",
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing_extensions as typing\n",
    "import json\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7H6Uod-qsu4I"
   },
   "source": [
    "## Exercise 1: Initialize the Generative Model and conduct a basic promt\n",
    "\n",
    "Let's start by veryifying that we can initialize and call a model. Ask it to write a poem about your country of origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j8QHPBS7vSXa"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"Enter you API Key here\")  # Enter your API key here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "MP05xKVpsu4I",
    "outputId": "9c3c701e-0ef3-45ef-e161-e1a19fcfdab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En Cuernavaca, la eterna primavera,\n",
      "El sabor se viste de luz y de quimera.\n",
      "La mesa llama, un festín morelense,\n",
      "Con aromas que al alma hacen florecer.\n",
      "\n",
      "De Yecapixtla, la cecina, fina y salada,\n",
      "Con crema y queso, una delicia dorada.\n",
      "Un bocado de sol, tendido en la tortilla,\n",
      "Que en cada fibra de Morelos brilla.\n",
      "\n",
      "Y los tacos acorazados, ¡qué invención!\n",
      "Con arroz y guiso, una explosión.\n",
      "De la calle el bullicio, sabor popular,\n",
      "Una fortaleza rica, para el hambre saciar.\n",
      "\n",
      "El mole verde, fresco, de pipián y hierbas,\n",
      "Recuerda el campo, sus verdes reservas.\n",
      "Las frutas dulces, con su néctar tan grato,\n",
      "Un festín tropical, del árbol al plato.\n",
      "\n",
      "Cuernavaca, en tu mesa hay un cantar,\n",
      "De Morelos el alma, lista para gustar.\n"
     ]
    }
   ],
   "source": [
    "# Use a supported model.\n",
    "# model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash-preview-05-20\")\n",
    "response = model.generate_content(\"Escribe un poema corto sobre comida de Cuernacava, Morelos Mexico\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Here we have different options with different models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "zyRe1zmDPbmV",
    "outputId": "4b2ae3db-ea4f-40c9-ba1e-f904df416efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En tierras del sol ardiente y sabor vibrante,\n",
      "la cocina mexicana, un festín constante.\n",
      "Maíz en tortillas, suaves al tacto,\n",
      "rellenas de carne, un suculento pacto.\n",
      "\n",
      "Chiles que arden, con fuego en la boca,\n",
      "salsas que bailan, al ritmo de la toca.\n",
      "Guacamole cremoso, verde y frescor,\n",
      "un manjar divino, un eterno amor.\n",
      "\n",
      "Tamales en hoja, un regalo escondido,\n",
      "mole misterioso, de sabor exquisito.\n",
      "De México lindo, su rica sazón,\n",
      "un abrazo cálido, en cada bocado y razón.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# For Gemini 1.5 Pro\n",
    "# model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Alternative model 2\n",
    "# model = genai.GenerativeModel(model_name=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "# Alternative model 3\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
    "\n",
    "response = model.generate_content(\"Escribe un poema corto sobre comida mexicana\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVFmKcRCsu4I"
   },
   "source": [
    "We will now be using the [Gemini API](https://ai.google.dev/api?lang=python) to synthetic responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyW-pGTBsu4I"
   },
   "source": [
    "## Exercise 4: Structured output\n",
    "You can ask a model to return structured output which makes it easier to post-process into statistics.\n",
    "\n",
    "1. Specify the output format\n",
    "2. Specify the input prompt template interested in.\n",
    "3. Specify a polulation - for now just a list\n",
    "4. Run the promp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "Ygx4MuGlsu4J",
    "outputId": "65446d9f-367c-4c8d-9216-0c458c663f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a 20-year old female from Thailand and working as student.\n",
      "[{'age': 20, 'food': 'Pad Krapow Moo Saap', 'location': 'Thailand', 'profession': 'student'}]\n",
      "You are a 20-year old male from Mexico and working as cashier.\n",
      "[{'age': 20, 'food': 'Sopa de tortilla', 'location': 'Mexico', 'profession': 'cashier'}]\n",
      "You are a 60-year old female from Spain and working as businessman.\n",
      "[{'age': 60, 'food': 'Bacalao al pil-pil', 'location': 'Spain', 'profession': 'businessman'}]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Specify the output format\n",
    "class MovieSpecification(typing.TypedDict):\n",
    "    age: int\n",
    "    location: str\n",
    "    food: str\n",
    "    profession: str\n",
    "\n",
    "# Step 2: Specify the input prompt template\n",
    "template = \"You are a {age}-year old {gender} from {location} and working as {profession}.\"\n",
    "\n",
    "# Step 3: specify a distribution - for now just a list.\n",
    "population = [\n",
    "    {\"age\":20, \"gender\":\"female\",\"location\":\"Thailand\",\"profession\":\"student\"},\n",
    "    {\"age\":20, \"gender\":\"male\",\"location\":\"Mexico\",\"profession\":\"cashier\"},\n",
    "    {\"age\":60, \"gender\":\"female\",\"location\":\"Spain\",\"profession\":\"businessman\"},\n",
    "    # TODO: add a couple more profiles here, by copy-pasting\n",
    "    #       and then modifying the line\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Step 4: run the survey\n",
    "for person in population:\n",
    "  system_prompt = template.format(**person)\n",
    "  model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20', system_instruction=system_prompt)\n",
    "  #model = genai.GenerativeModel('gemini-2.0-flash', system_instruction=system_prompt)\n",
    "  response = model.generate_content(\n",
    "      \"\"\"\n",
    "      Cuál es tu comida favorita para la cena? Evita responder con un estereotipo de comida\n",
    "      y menciona una comida de la cocina de tu localidad que disfrutas mucho.\n",
    "      \"\"\",\n",
    "      generation_config = genai.GenerationConfig(\n",
    "          response_mime_type=\"application/json\", response_schema=list[MovieSpecification]\n",
    "      ),\n",
    "  )\n",
    "\n",
    "  print(system_prompt)\n",
    "  print(json.loads(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0mLnFtpYvsO"
   },
   "source": [
    "## Exercise 5: Encuesta Nacional Seguridad Urbana (ENSU)\n",
    "\n",
    "In the following code.\n",
    "\n",
    "1. We will randomly select \"n\" individual responses\n",
    "2. We will pass demographics features to the AI model\n",
    "3. Wi will generate synthetic responses based on real demographics\n",
    "4. Compare real results with synthetic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eQmBjqt8NXpo"
   },
   "outputs": [],
   "source": [
    "####  function for maping the column SEXO into textual values\n",
    "import pandas as pd\n",
    "\n",
    "def map_sexo_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Maps numeric SEXO values to categorical labels.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): A DataFrame containing the column 'SEXO'\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A copy of the DataFrame with 'SEXO' values mapped\n",
    "    \"\"\"\n",
    "    sexo_map = {\n",
    "        1: \"Hombre\",\n",
    "        2: \"Mujer\"\n",
    "    }\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    df[\"SEXO\"] = df[\"SEXO\"].map(sexo_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fa41NH3MYszQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "ensu = pd.read_csv(\"https://www.dropbox.com/scl/fi/nsopocoldxc4xo0jwxt2a/ENSU_Dic_2024.csv?rlkey=1ss4nl2j612xjooax10ldc9lr&dl=1\")\n",
    "\n",
    "ensu = map_sexo_column(ensu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN9jFlrDBKOi"
   },
   "source": [
    "### **Conduct a descriptive data analysis on the variables of interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRR13b0I6Uxc",
    "outputId": "9c2486e7-8afa-439c-ef90-36f97a33b792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Numeric Descriptive Statistics ===\n",
      "               EDAD         BP1_1      BP1_2_01      BP1_2_02      BP1_2_03  \\\n",
      "count  23451.000000  23451.000000  23451.000000  23451.000000  23451.000000   \n",
      "mean      46.380922      1.608673      1.179779      1.772803      1.530852   \n",
      "std       17.286217      0.625329      0.419668      0.888627      0.574008   \n",
      "min       18.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "25%       32.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "50%       45.000000      2.000000      1.000000      1.000000      2.000000   \n",
      "75%       59.000000      2.000000      1.000000      3.000000      2.000000   \n",
      "max       98.000000      9.000000      9.000000      9.000000      9.000000   \n",
      "\n",
      "           BP1_2_04  \n",
      "count  23451.000000  \n",
      "mean       2.925845  \n",
      "std        0.690232  \n",
      "min        1.000000  \n",
      "25%        3.000000  \n",
      "50%        3.000000  \n",
      "75%        3.000000  \n",
      "max        9.000000  \n",
      "\n",
      "=== Categorical Frequency Counts ===\n",
      "\n",
      "-- SEXO --\n",
      "SEXO\n",
      "Mujer     12997\n",
      "Hombre    10454\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- BP1_1 --\n",
      "BP1_1\n",
      "2    13762\n",
      "1     9625\n",
      "9       64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- BP1_2_01 --\n",
      "BP1_2_01\n",
      "1    19319\n",
      "2     4120\n",
      "9       12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- BP1_2_02 --\n",
      "BP1_2_02\n",
      "1    12213\n",
      "3     6780\n",
      "2     4443\n",
      "9       15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- BP1_2_03 --\n",
      "BP1_2_03\n",
      "2    11811\n",
      "1    11399\n",
      "3      215\n",
      "9       26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- BP1_2_04 --\n",
      "BP1_2_04\n",
      "3    21789\n",
      "1     1253\n",
      "2      241\n",
      "9      168\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Subset the relevant columns\n",
    "selected_columns = [\"SEXO\", \"EDAD\", \"BP1_1\", \"BP1_2_01\", \"BP1_2_02\", \"BP1_2_03\", \"BP1_2_04\"]\n",
    "df = ensu[selected_columns]\n",
    "\n",
    "# Descriptive statistics for numerical columns\n",
    "numeric_stats = df.describe()\n",
    "\n",
    "# Frequency counts for categorical columns\n",
    "categorical_stats = {}\n",
    "for col in [\"SEXO\", \"BP1_1\", \"BP1_2_01\", \"BP1_2_02\", \"BP1_2_03\", \"BP1_2_04\"]:\n",
    "    categorical_stats[col] = df[col].value_counts(dropna=False)\n",
    "\n",
    "# Print results\n",
    "print(\"=== Numeric Descriptive Statistics ===\")\n",
    "print(numeric_stats)\n",
    "\n",
    "print(\"\\n=== Categorical Frequency Counts ===\")\n",
    "for col, counts in categorical_stats.items():\n",
    "    print(f\"\\n-- {col} --\")\n",
    "    print(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLPvUb-bDq45"
   },
   "source": [
    "### **Randomly selecting n observations for the ENSU survey**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "svECUv91JuEi"
   },
   "outputs": [],
   "source": [
    "# Randomly select n rows\n",
    "ensu_sample = ensu.sample(n=10, random_state=896)  # Set random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "IqT_dwFAb5YW",
    "outputId": "459fd7ac-025f-456a-b851-715b07429f73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"ensu_sample[[\\\"NOM_MUN\\\", \\\"SEXO\\\", \\\"EDAD\\\",\\\"BP1_1\\\"]]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"NOM_MUN\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"MERIDA\",\n          \"AGUASCALIENTES\",\n          \"CHIHUAHUA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SEXO\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Hombre\",\n          \"Mujer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EDAD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 19,\n        \"max\": 76,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          59,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BP1_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-7b34087f-fc53-4a5d-81fc-f59e3acdf613\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOM_MUN</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>BP1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>ACAPULCO DE JUAREZ</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>AGUASCALIENTES</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>TUXTLA GUTIERREZ</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>QUERETARO</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>MANZANILLO</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>CHIHUAHUA</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23333</th>\n",
       "      <td>GUADALUPE</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22663</th>\n",
       "      <td>MERIDA</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9108</th>\n",
       "      <td>LEON</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b34087f-fc53-4a5d-81fc-f59e3acdf613')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7b34087f-fc53-4a5d-81fc-f59e3acdf613 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7b34087f-fc53-4a5d-81fc-f59e3acdf613');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-43fb6c87-868f-4dc7-83e2-098dd7860dec\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43fb6c87-868f-4dc7-83e2-098dd7860dec')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-43fb6c87-868f-4dc7-83e2-098dd7860dec button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                  NOM_MUN    SEXO  EDAD  BP1_1\n",
       "9753   ACAPULCO DE JUAREZ   Mujer    76      1\n",
       "42         AGUASCALIENTES  Hombre    39      2\n",
       "133        AGUASCALIENTES  Hombre    19      2\n",
       "3563     TUXTLA GUTIERREZ  Hombre    42      2\n",
       "17995           QUERETARO  Hombre    53      2\n",
       "2940           MANZANILLO   Mujer    51      1\n",
       "3845            CHIHUAHUA   Mujer    58      1\n",
       "23333           GUADALUPE  Hombre    74      2\n",
       "22663              MERIDA  Hombre    59      2\n",
       "9108                 LEON   Mujer    20      2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensu_sample[[\"NOM_MUN\", \"SEXO\", \"EDAD\",\"BP1_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "wMoBzk1ut9GA",
    "outputId": "3394bb43-0e43-432d-f25a-0de7d6845716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              NOM_MUN    SEXO  EDAD  response_code         response_label\n",
      "0  ACAPULCO DE JUAREZ   Mujer    76              3  No sabe / no responde\n",
      "1      AGUASCALIENTES  Hombre    39              2               Inseguro\n",
      "2      AGUASCALIENTES  Hombre    19              1                 Seguro\n",
      "3    TUXTLA GUTIERREZ  Hombre    42              2               Inseguro\n",
      "4           QUERETARO  Hombre    53              2               Inseguro\n",
      "5          MANZANILLO   Mujer    51              1                 Seguro\n",
      "6           CHIHUAHUA   Mujer    58              2               Inseguro\n",
      "7           GUADALUPE  Hombre    74              2               Inseguro\n",
      "8              MERIDA  Hombre    59              1                 Seguro\n",
      "9                LEON   Mujer    20              2               Inseguro\n"
     ]
    }
   ],
   "source": [
    "###  Example 1.  We are using short prompt\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing_extensions import TypedDict\n",
    "import google.generativeai as genai\n",
    "\n",
    "# 1. Assume ensu_sample is already loaded as a pandas DataFrame.\n",
    "\n",
    "# Select only the variables city, sex, and age\n",
    "ensu_sel = ensu_sample[[\"NOM_MUN\", \"SEXO\", \"EDAD\"]]\n",
    "\n",
    "# 2. Define the survey question template\n",
    "survey_questions = {\n",
    "    \"BP1_1\": \"En términos de delincuencia, ¿considera que vivir en {NOM_MUN} es…\"\n",
    "}\n",
    "\n",
    "#3. Define the response mapping dictionary\n",
    "BP1_dic = {\n",
    "    1: \"Seguro\",\n",
    "    2: \"Inseguro\",\n",
    "    3: \"No sabe / no responde\"\n",
    "}\n",
    "\n",
    "# 4. Define expected JSON output schema\n",
    "class SurveyResponse(TypedDict):\n",
    "    response_code: int\n",
    "\n",
    "# 5. Loop over each selected individual, ask the question, and map the answer\n",
    "responses = []\n",
    "for _, row in ensu_sel.iterrows():\n",
    "    system_prompt = f\"Tu eres {row['SEXO']}-que tiene {row['EDAD']}- años de edad y originario de {row['NOM_MUN']}.\"\n",
    "    question = survey_questions[\"BP1_1\"].format(NOM_MUN=row[\"NOM_MUN\"])\n",
    "\n",
    "    # Initialize model\n",
    "    model = genai.GenerativeModel(\n",
    "        \"gemini-2.5-flash-preview-05-20\",\n",
    "        #\"gemini-1.5-pro\",\n",
    "        #\"gemini-1.5-flash\",\n",
    "        #\"gemini-2.0-flash\",\n",
    "        system_instruction=system_prompt\n",
    "    )\n",
    "\n",
    "    # Generate content\n",
    "    response = model.generate_content(\n",
    "        f\"Responde esta pregunta as JSON: {{\\\"response_code\\\": [1, 2, or 3]}}.\\n\\nQuestion: {question}\",\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=SurveyResponse\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Parse response\n",
    "    try:\n",
    "        resp_json = json.loads(response.text)\n",
    "        code = resp_json.get(\"response_code\", None)\n",
    "    except Exception as e:\n",
    "        code = None  # In case of failure, fallback to None\n",
    "\n",
    "    label = BP1_dic.get(code, \"Unknown\")\n",
    "\n",
    "    responses.append({\n",
    "      \"NOM_MUN\": row[\"NOM_MUN\"],\n",
    "      \"SEXO\": row[\"SEXO\"],\n",
    "      \"EDAD\": row[\"EDAD\"],\n",
    "      \"response_code\": code,\n",
    "      \"response_label\": label\n",
    "  })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(responses)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FMYw15vEBqa"
   },
   "source": [
    "### **We create a function for calculating the accuracy and the error in the LLM models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-k2TsRxt_BNY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_llm_responses(results_df: pd.DataFrame, ensu_sample: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Join on NOM_MUN, SEXO, and EDAD, then compare response_code with BP1_1.\n",
    "    Computes accuracy and confusion matrix.\n",
    "\n",
    "    Returns:\n",
    "        accuracy (float): % of correct matches\n",
    "        conf_matrix (pd.DataFrame): Confusion matrix as DataFrame\n",
    "    \"\"\"\n",
    "    # Merge based on key identifiers\n",
    "    merged = pd.merge(\n",
    "        results_df,\n",
    "        ensu_sample[[\"NOM_MUN\", \"SEXO\", \"EDAD\", \"BP1_1\"]],\n",
    "        on=[\"NOM_MUN\", \"SEXO\", \"EDAD\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Drop rows where predictions or true labels are missing\n",
    "    merged = merged.dropna(subset=[\"response_code\", \"BP1_1\"])\n",
    "\n",
    "    # Accuracy\n",
    "    correct = (merged[\"response_code\"] == merged[\"BP1_1\"]).sum()\n",
    "    total = len(merged)\n",
    "    accuracy = (correct / total) * 100 if total > 0 else 0.0\n",
    "\n",
    "    # Confusion matrix\n",
    "    labels = sorted(merged[\"BP1_1\"].dropna().unique())\n",
    "    cm = confusion_matrix(\n",
    "        merged[\"BP1_1\"], merged[\"response_code\"], labels=labels\n",
    "    )\n",
    "    cm_df = pd.DataFrame(cm, index=[f\"True_{i}\" for i in labels], columns=[f\"Pred_{i}\" for i in labels])\n",
    "\n",
    "    return accuracy, cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3HUuP4EAQR1",
    "outputId": "d6a7f682-87eb-4f49-b9eb-7e03ccbc25c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.00%\n",
      "Confusion Matrix:\n",
      "        Pred_1  Pred_2\n",
      "True_1       1       1\n",
      "True_2       2       5\n"
     ]
    }
   ],
   "source": [
    "accuracy, conf_matrix = evaluate_llm_responses(results_df, ensu_sample)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "sBxK0CGeeTpD",
    "outputId": "511da22e-81d0-473c-de42-00b230d42e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              NOM_MUN    SEXO  EDAD  response_code response_label\n",
      "0  ACAPULCO DE JUAREZ   Mujer    76              2      Inseguro?\n",
      "1      AGUASCALIENTES  Hombre    39              2      Inseguro?\n",
      "2      AGUASCALIENTES  Hombre    19              2      Inseguro?\n",
      "3    TUXTLA GUTIERREZ  Hombre    42              2      Inseguro?\n",
      "4           QUERETARO  Hombre    53              1        Seguro?\n",
      "5          MANZANILLO   Mujer    51              2      Inseguro?\n",
      "6           CHIHUAHUA   Mujer    58              2      Inseguro?\n",
      "7           GUADALUPE  Hombre    74              2      Inseguro?\n",
      "8              MERIDA  Hombre    59              1        Seguro?\n",
      "9                LEON   Mujer    20              2      Inseguro?\n"
     ]
    }
   ],
   "source": [
    "### EXAMPLE 2.  We are using a more descriptive prompt\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing_extensions import TypedDict\n",
    "import google.generativeai as genai\n",
    "\n",
    "# 1. Assume ensu_sample is already loaded as a pandas DataFrame.\n",
    "\n",
    "# Select only the variables city, sex, and age\n",
    "ensu_sel = ensu_sample[[\"NOM_MUN\", \"SEXO\", \"EDAD\"]]\n",
    "\n",
    "# 2. Define the survey question template\n",
    "survey_questions = {\n",
    "    \"BP1_1\": \"En términos de delincuencia, ¿considera que vivir actualmente en {NOM_MUN} es…\"\n",
    "}\n",
    "\n",
    "#3. Define the response mapping dictionary\n",
    "BP1_dic = {\n",
    "    1: \"Seguro?\",\n",
    "    2: \"Inseguro?\",\n",
    "    3: \"No sabe / no responde\"\n",
    "}\n",
    "\n",
    "# 4. Define expected JSON output schema\n",
    "class SurveyResponse(TypedDict):\n",
    "    response_code: int\n",
    "\n",
    "# 5. Loop over each selected individual, ask the question, and map the answer\n",
    "responses = []\n",
    "for _, row in ensu_sel.iterrows():\n",
    "    system_prompt = (\n",
    "    f\"Eres una persona de sexo {row['SEXO']}, tienes {row['EDAD']} años, y vives en el municipio de {row['NOM_MUN']}. \"\n",
    "    f\"Conoces bien la situación de seguridad pública y crimen en {row['NOM_MUN']}, ya que has leído noticias, has visto información en redes sociales, \"\n",
    "    f\"y has conversado con tus vecinos. Basa tus respuestas en tu conocimiento sobre la situación seguridad pública  en {row['NOM_MUN']}.\"\n",
    "    f\"Manten tus respestas ecuánimes y objetivas \"\n",
    "    )\n",
    "\n",
    "    question = survey_questions[\"BP1_1\"].format(NOM_MUN=row[\"NOM_MUN\"])\n",
    "\n",
    "    # Initialize model\n",
    "    model = genai.GenerativeModel(\n",
    "        \"gemini-2.5-flash-preview-05-20\",\n",
    "        #\"gemini-1.5-pro\",\n",
    "        #\"gemini-1.5-flash\",\n",
    "        #\"gemini-2.0-flash\",\n",
    "        system_instruction=system_prompt\n",
    "    )\n",
    "\n",
    "    # Generate content\n",
    "    prompt = f\"\"\"\n",
    "    Responde esta pregunta como un número JSON válido según las siguientes reglas:\n",
    "\n",
    "    1: \"Seguro?\" — si te sientes seguro o segura cuando vives en {row['NOM_MUN']}\n",
    "    2: \"Inseguro?\" — si te sientes inseguro o insegura cuando vive en {row['NOM_MUN']}\n",
    "    3: \"No sabe / no responde\" — si no sabes o no puedes responder\n",
    "\n",
    "    Devuelve solo el siguiente formato JSON:\n",
    "    {{\"response_code\": 1}}, {{\"response_code\": 2}}, o {{\"response_code\": 3}}\n",
    "\n",
    "    Pregunta: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(\n",
    "        prompt.strip(),\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=SurveyResponse\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Parse response\n",
    "    try:\n",
    "        resp_json = json.loads(response.text)\n",
    "        code = resp_json.get(\"response_code\", None)\n",
    "    except Exception as e:\n",
    "        code = None  # In case of failure, fallback to None\n",
    "\n",
    "    label = BP1_dic.get(code, \"Unknown\")\n",
    "\n",
    "    responses.append({\n",
    "      \"NOM_MUN\": row[\"NOM_MUN\"],\n",
    "      \"SEXO\": row[\"SEXO\"],\n",
    "      \"EDAD\": row[\"EDAD\"],\n",
    "      \"response_code\": code,\n",
    "      \"response_label\": label\n",
    "  })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(responses)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "au8CMktlPIhK",
    "outputId": "b8de73ea-8258-4b82-fd83-c230ea20b3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n",
      "Confusion Matrix:\n",
      "        Pred_1  Pred_2\n",
      "True_1       0       3\n",
      "True_2       2       5\n"
     ]
    }
   ],
   "source": [
    "accuracy, conf_matrix = evaluate_llm_responses(results_df, ensu_sample)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
